{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Credentials\n",
    "load credentials from id.json into env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open('id.json', 'r') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "os.environ[\"SPOTIPY_CLIENT_ID\"] = data[\"client_id\"]\n",
    "os.environ[\"SPOTIPY_CLIENT_SECRET\"] = data[\"client_secret\"]\n",
    "os.environ[\"SPOTIPY_REDIRECT_URI\"] = r'http://localhost:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all liked songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "scope = \"user-library-read\"\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))\n",
    "\n",
    "results = []\n",
    "\n",
    "offset = 0\n",
    "num_songs_total = sp.current_user_saved_tracks(limit=1)['total']\n",
    "\n",
    "# Information returned in batches in dictionary\n",
    "while offset < num_songs_total:\n",
    "    print(f\"Processing batch: {offset}/{num_songs_total}\", end='\\r')\n",
    "    curr_batch = sp.current_user_saved_tracks(limit=50, offset=offset)['items']\n",
    "    for track in curr_batch:\n",
    "        res = track['track']\n",
    "        del res['available_markets']\n",
    "        del res['album']['available_markets']\n",
    "        results.append(res)\n",
    "        \n",
    "    offset += 50\n",
    "    \n",
    "print(\"\\nFinished loading liked songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get audio features for all liked songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "batch_size = 100\n",
    "while offset < num_songs_total:\n",
    "    # compile list to give query\n",
    "    print(f\"Processing batch: {offset}/{num_songs_total}\", end='\\r')\n",
    "    uri_list = []\n",
    "\n",
    "    curr_size = min(batch_size, num_songs_total - offset)\n",
    "    for i in range(curr_size):\n",
    "        uri_list.append(results[offset+i][\"uri\"])\n",
    "\n",
    "    # conduct query\n",
    "    curr_batch = sp.audio_features(uri_list)\n",
    "\n",
    "    # associate query result with existing results dictionary\n",
    "    keys_i_hate = ['id', 'type', 'uri', 'track_href', 'analysis_url', 'duration_ms', 'time_signature']\n",
    "    for i in range(curr_size):\n",
    "        for key in keys_i_hate:\n",
    "            del curr_batch[i][key]\n",
    "        results[offset+i][\"audio_features\"] =  curr_batch[i]\n",
    "\n",
    "    # increment batch (can also be done outside of loop)\n",
    "    offset += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Liked Songs using metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert audio feature dict into numpy array for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "audio_features = list(results[0]['audio_features'].keys())\n",
    "\n",
    "audio_features_arr = np.zeros((num_songs_total, len(audio_features)))\n",
    "\n",
    "for i in range(num_songs_total):\n",
    "    for j, audio_feature in enumerate(audio_features):\n",
    "        audio_features_arr[i][j] = results[i]['audio_features'][audio_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(audio_features_arr)\n",
    "\n",
    "std_data = sc.transform(audio_features_arr)\n",
    "\n",
    "num_comp = 2\n",
    "pca = PCA(n_components=num_comp)\n",
    "pca.fit(std_data)\n",
    "pca_result = pca.transform(std_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "TSNE = TSNE(n_components=2, perplexity=50, n_iter=5000, learning_rate=200)\n",
    "\n",
    "tsne_results = TSNE.fit_transform(std_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(audio_features)):\n",
    "    # visualize\n",
    "    df_tsne = pd.DataFrame(tsne_results, columns=['t-sne-one', 't-sne-two'])\n",
    "    df_tsne['label'] = audio_features_arr[:,i]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.scatterplot(\n",
    "        x=\"t-sne-one\", y=\"t-sne-two\",\n",
    "        hue=\"label\",\n",
    "        data=df_tsne,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plt.title(audio_features[i])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0c1e4d562b5f812171e22f6ff609450df3e58f284a941217b67c967f7209e2f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('spotify_moods')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
